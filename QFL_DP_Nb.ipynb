{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb67703-b72b-474e-8e62-e710cfdfa9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from pyvacy import optim, analysis, sampling\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "from metaquantum.CircuitComponents import VariationalQuantumClassifierInterBlock_M_IN_N_OUT\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import tensor\n",
    "import csv\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import pennylane as qml\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50a0dc36",
   "metadata": {},
   "source": [
    "Paramaters for QFL-DP Model and Initializaition of VQC from metaquantum inteface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e448ff-b808-4109-8b13-cbf1100cbc28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VariationalQuantumClassifierInterBlock_M_IN_N_OUT:\n",
    "\tdef __init__(\n",
    "\t\t\tself,\n",
    "\t\t\tnum_of_input= 10,\n",
    "\t\t\tnum_of_output= 4,\n",
    "\t\t\tnum_of_wires = 10,\n",
    "\t\t\tnum_of_layers = 2,\n",
    "\t\t\tvar_Q_circuit = None,\n",
    "\t\t\tvar_Q_bias = None,\n",
    "\t\t\tqdevice = \"default.qubit\",\n",
    "\t\t\thadamard_gate = False,\n",
    "\t\t\tmore_entangle = False,\n",
    "\t\t\tgpu = False):\n",
    "\n",
    "\t\tself.var_Q_circuit = var_Q_circuit\n",
    "\t\tself.var_Q_bias = var_Q_bias\n",
    "\t\tself.num_of_input = num_of_input\n",
    "\t\tself.num_of_output = num_of_output\n",
    "\t\tself.num_of_wires = num_of_wires\n",
    "\t\tself.num_of_layers = num_of_layers\n",
    "\n",
    "\t\tself.qdevice = qdevice\n",
    "\n",
    "\t\tself.hadamard_gate = hadamard_gate\n",
    "\t\tself.more_entangle = more_entangle\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\tif gpu == True and qdevice == \"qulacs.simulator\":\n",
    "\t\t\tprint(\"GOT QULACS AND GPU\")\n",
    "\t\t\tself.dev = qml.device(self.qdevice, wires = num_of_wires, gpu = True)\n",
    "\t\telse:\n",
    "\t\t\tself.dev = qml.device(self.qdevice, wires = num_of_wires)\n",
    "\n",
    "\n",
    "\tdef set_params(self, var_Q_circuit, var_Q_bias):\n",
    "\t\tself.var_Q_circuit = var_Q_circuit\n",
    "\t\tself.var_Q_bias = var_Q_bias\n",
    "\n",
    "\tdef init_params(self):\n",
    "\t\tself.var_Q_circuit = Variable(torch.tensor(0.01 * np.random.randn(self.num_of_layers, self.num_of_wires, 3), device=device).type(dtype), requires_grad=True)\n",
    "\t\treturn self.var_Q_circuit\n",
    "\n",
    "\tdef _statepreparation(self, angles):\n",
    "\n",
    "\t\t\"\"\"Quantum circuit to encode a the input vector into variational params\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\ta: feature vector of rad and rad_square => np.array([rad_X_0, rad_X_1, rad_square_X_0, rad_square_X_1])\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif self.hadamard_gate == True:\n",
    "\t\t\tfor i in range(self.num_of_input):\n",
    "\t\t\t\tqml.Hadamard(wires=i)\n",
    "\n",
    "\t\tfor i in range(self.num_of_input):\n",
    "\t\t\tqml.RY(angles[i,0], wires=i)\n",
    "\t\t\tqml.RZ(angles[i,1], wires=i)\n",
    "\n",
    "\tdef _layer(self, W):\n",
    "\t\t\"\"\" Single layer of the variational classifier.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tW (array[float]): 2-d array of variables for one layer\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\n",
    "\t\t# Entanglement Layer\n",
    "\n",
    "\t\tfor i in range(self.num_of_wires):\n",
    "\t\t\tqml.CNOT(wires=[i, (i + 1) % self.num_of_wires])\n",
    "\n",
    "\t\tif self.more_entangle == True:\n",
    "\t\t\tfor j in range(self.num_of_wires):\n",
    "\t\t\t\tqml.CNOT(wires=[j, (j + 2) % self.num_of_wires])\n",
    "\n",
    "\t\t# Rotation Layer\n",
    "\t\tfor j in range(self.num_of_wires):\n",
    "\t\t\tqml.Rot(W[j, 0], W[j, 1], W[j, 2], wires=j)\n",
    "\n",
    "\tdef circuit(self, angles):\n",
    "\n",
    "\t\t@qml.qnode(self.dev, interface='torch')\n",
    "\t\tdef _circuit(var_Q_circuit, angles):\n",
    "\t\t\t\"\"\"The circuit of the variational classifier.\"\"\"\n",
    "\t\t\n",
    "\t\t\tself._statepreparation(angles)\n",
    "\n",
    "\t\t\tweights = var_Q_circuit\n",
    "\t\t\t\n",
    "\t\t\tfor W in weights:\n",
    "\t\t\t\tself._layer(W)\n",
    "\n",
    "\t\t\t\n",
    "\t\t\treturn [qml.expval(qml.PauliZ(k)) for k in range(self.num_of_output)]\n",
    "\n",
    "\t\treturn _circuit(self.var_Q_circuit, angles)\n",
    "\n",
    "\tdef _forward(self, angles):\n",
    "\t\t\"\"\"The variational classifier.\"\"\"\n",
    "\t\t\n",
    "\t\tbias = self.var_Q_bias \n",
    "\n",
    "\t\t\n",
    "\t\traw_output = self.circuit(angles)\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\treturn raw_output\n",
    "\n",
    "\tdef forward(self, angles):\n",
    "\t\n",
    "\t\tfw = self._forward(angles)\n",
    "\t\treturn fw\n",
    "\n",
    "dtype = torch.cuda.DoubleTensor if torch.cuda.is_available() else torch.DoubleTensor\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "qdevice = \"default.qubit\"\n",
    "\n",
    "params = {'isQuantum': True, 'usePyvacy': True, 'useGpu': True, \n",
    "         'epochs': 1, 'delta': 1e-05,'l2_clip': 0.1, \n",
    "          'l2_penalty': 0.001,'lr': 0.02, 'micro_bs': 16, 'mini_bs': 128, 'noise':1.5, 'noise_min' : 1.5,\n",
    "          'noise_max':2.0, 'noise_incr' : 0.5, 'rounds': 1, 'selected': 5,'clients':100, 'runs':1, \n",
    "         'eps_vs_acc': True, 'optimizer': 'SGD'}\n",
    "\n",
    "\n",
    "vqc = VariationalQuantumClassifierInterBlock_M_IN_N_OUT(\n",
    "    num_of_input=4,\n",
    "    num_of_output=2,\n",
    "    num_of_wires=4,\n",
    "    num_of_layers=2,\n",
    "    qdevice=qdevice,\n",
    "    hadamard_gate=False,\n",
    "    more_entangle=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c01bac7",
   "metadata": {},
   "source": [
    "Torch wrapper class for VQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f5f3a8-5458-4122-9448-1d5148cf6147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "class VQCTorch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.q_params = nn.Parameter(0.01 * torch.randn(2, 4, 3))\n",
    "\n",
    "    def get_angles_atan(self, in_x):\n",
    "        return torch.stack([torch.stack([torch.atan(item), torch.atan(item ** 2)]) for item in in_x])\n",
    "\n",
    "    def forward(self, batch_item):\n",
    "        # print('line 99')\n",
    "        vqc.var_Q_circuit = self.q_params\n",
    "        # print(self.vqc, 'at line 100')\n",
    "        score_batch = []\n",
    "\n",
    "        for single_item in batch_item:\n",
    "            res_temp = self.get_angles_atan(single_item)\n",
    "            # print(res_temp)\n",
    "\n",
    "            # print(self.vqc, 'at line 107')\n",
    "            q_out_elem = vqc.forward(res_temp)\n",
    "            # print(q_out_elem)\n",
    "\n",
    "            clamp = 1e-9\n",
    "            \n",
    "            # pdb.set_trace()\n",
    "            normalized_output = torch.clamp(torch.stack(q_out_elem), min=clamp)\n",
    "            score_batch.append(normalized_output)\n",
    "\n",
    "        scores = torch.stack(score_batch).view(len(batch_item), 2)\n",
    "\n",
    "        return scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90c9fb28",
   "metadata": {},
   "source": [
    "Data loading for Cats vs Dogs datasest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b209f5-928c-42fb-ab7b-81352d7a399b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/global/u2/r/rr637/QPPAI-FL/data/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[1;32m     20\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/global/u2/r/rr637/QPPAI-FL/data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 23\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x: datasets\u001b[38;5;241m.\u001b[39mImageFolder(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     24\u001b[0m     data_dir, x), data_transforms[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     28\u001b[0m dataset_sizes \u001b[38;5;241m=\u001b[39m {x: \u001b[38;5;28mlen\u001b[39m(image_datasets[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     29\u001b[0m class_names \u001b[38;5;241m=\u001b[39m image_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclasses\n",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[1;32m     20\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/global/u2/r/rr637/QPPAI-FL/data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 23\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x: \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     28\u001b[0m dataset_sizes \u001b[38;5;241m=\u001b[39m {x: \u001b[38;5;28mlen\u001b[39m(image_datasets[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     29\u001b[0m class_names \u001b[38;5;241m=\u001b[39m image_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mclasses\n",
      "File \u001b[0;32m~/anaconda3/envs/SULI/lib/python3.10/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/anaconda3/envs/SULI/lib/python3.10/site-packages/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m~/anaconda3/envs/SULI/lib/python3.10/site-packages/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SULI/lib/python3.10/site-packages/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/global/u2/r/rr637/QPPAI-FL/data/train'"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(\n",
    "            224, scale=(0.96, 1.0), ratio=(0.95, 1.05)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "####\n",
    "print(device)\n",
    "\n",
    "data_dir = '/global/u2/r/rr637/QPPAI-FL/data/'\n",
    "\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(\n",
    "    data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "print(class_names)\n",
    "print(f\"Train image size: {dataset_sizes['train']}\")\n",
    "print(f'Validation image size: {dataset_sizes[\"val\"]}')\n",
    "####\n",
    "\n",
    "# Dividing the training data into num_clients, with each client having equal number of images\n",
    "\n",
    "traindata = image_datasets['train']\n",
    "client_train_size = int(dataset_sizes['train'] / params['clients'])\n",
    "print(f\"client_train_size: {client_train_size}\")\n",
    "\n",
    "if params['usePyvacy']:\n",
    "    epsilon = analysis.epsilon(dataset_sizes['train'],params['mini_bs'],\n",
    "                                    params['noise'], params['rounds'],params['delta'])\n",
    "    params['epsilon'] = epsilon\n",
    "    \n",
    "    print(epsilon)\n",
    "\n",
    "traindata_split = torch.utils.data.random_split(traindata,\n",
    "                                                [client_train_size for _ in range(params['clients'])])\n",
    "\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(\n",
    "    x, batch_size=params['mini_bs'], shuffle=True) for x in traindata_split]\n",
    "\n",
    "\n",
    "\n",
    "# Loading the test iamges and thus converting them into a test_loader\n",
    "testdata = image_datasets['val']\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testdata, batch_size=params['mini_bs'], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07189501",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full hybird quantumm classical model with fully classical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d567062-3674-4a98-8b64-e07e7f555aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuantumTransfer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torchvision.models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.net.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4, bias=True),\n",
    "            VQCTorch())\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        return self.net(in_x)\n",
    "\n",
    "class ClassicalTransfer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torchvision.models.vgg16(weights='VGG16_Weights.DEFAULT')\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.net.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=4, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=4, out_features=2, bias=True),\n",
    "        )\n",
    "            \n",
    "\n",
    "    def forward(self, in_x):\n",
    "        return self.net(in_x)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "528097e6",
   "metadata": {},
   "source": [
    "Differentially private local updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46939e-6dbf-4303-9b3a-11471ea79f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def client_update(client_model, optimizer, train_loader, epoch, index, r):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data with differential privacy\n",
    "    \"\"\"\n",
    "\n",
    "    client_model.train()\n",
    "    client_model = client_model.to(device)\n",
    "    loss_list = []\n",
    "    acc_list =[]\n",
    "    if params['usePyvacy']:\n",
    "        \n",
    "        for e in range(params['epochs']):\n",
    "            print(\"EPOCH: \", e)\n",
    "            acc_mini = []\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                # print(\"BATCH IDX: \", batch_idx)\n",
    "                data, target = data.to(device), target.to(device)\n",
    "               \n",
    "                optimizer.zero_grad()\n",
    "                acc_micro = []\n",
    "                for microbatch_idx, (microbatch_data, microbatch_target) in enumerate(\n",
    "                        zip(data.split(optimizer.microbatch_size), target.split(optimizer.microbatch_size))):\n",
    "#                    \n",
    "                    microbatch_data, microbatch_target = microbatch_data.to(\n",
    "                        device), microbatch_target.to(device)\n",
    "#                     print(microbatch_data.dtype, microbatch_target.dtype)\n",
    "#                     if (params['useGpu'] and not microbatch_data.is_cuda):\n",
    "#                         print(\"moving microbatch to cuda...\")\n",
    "#                         microbatch_data = microbatch_data.cuda()\n",
    "#                         microbatch_target = microbatch_target.cuda()\n",
    "                    optimizer.zero_microbatch_grad() \n",
    "                    output = client_model(microbatch_data)\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "#        \n",
    "                    loss = criterion(output, microbatch_target)\n",
    "                    \n",
    "                    # print(\"WithDP-Loss: \", loss.item())\n",
    "                   \n",
    "                    loss.backward()\n",
    "#                     client_model.update_l2_norm_list(optimizer, isDP=False)\n",
    "                    optimizer.microbatch_step()\n",
    "                    preds = torch.argmax(output, dim=1).to(device)\n",
    "                    # print(f\"Shape of target: {microbatch_target.shape} and preds: {preds.shape}\", microbatch_target, preds)\n",
    "                    \n",
    "                    accuracy = accuracy_score(microbatch_target.cpu().numpy(), preds.cpu().numpy())\n",
    "                    acc_micro.append(accuracy)\n",
    "                    # print(\"Accuracy = {}\".format(accuracy))\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "                    \n",
    "                    \n",
    "                micro_avg = sum(acc_micro)/len(acc_micro)\n",
    "                acc_mini.append(micro_avg)\n",
    "                optimizer.step()\n",
    "#                 client_model.update_l2_norm_list(optimizer, isDP=True)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            \n",
    "                # correct += output.eq(target.view_as(output)).sum().item()\n",
    "            # acc = correct / len(client_test_loader.dataset)\n",
    "            mini_avg = sum(acc_mini)/len(acc_mini)\n",
    "            acc_list.append(mini_avg)\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "        \n",
    "            \n",
    "            print(f\"Loss per epoch: {loss.item()}\")\n",
    "            print(f\"Epoch {e} Accuracy: {mini_avg}\")\n",
    "                \n",
    "    else:\n",
    "            \n",
    "        for e in range(epoch):\n",
    "            acc_mini = []\n",
    "            print(\"Client: \",index+1)\n",
    "            acc_mini=[]\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                # print(\"BATCH IDX: \", batch_idx)\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = client_model(data)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                # loss = F.nll_loss(output, target)\n",
    "                loss = criterion(output, target)\n",
    "                # print(\"withoutDP-Loss: \", loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                preds = torch.argmax(output, dim=1).to(device)\n",
    "                accuracy = accuracy_score(target.cpu().numpy(), preds.cpu().numpy())\n",
    "                print(f\"accuracy_per_mini: {accuracy}\")\n",
    "                acc_mini.append(accuracy)\n",
    "        \n",
    "            \n",
    "            print(f\"Loss per epoch: {loss.item()}\")\n",
    "            print(f\"acc_mini_list: {acc_mini}\")\n",
    "            mini_avg = sum(acc_mini)/len(acc_mini)\n",
    "            print(f\"Epoch {e} Accuracy: {mini_avg}\")\n",
    "            acc_list.append(mini_avg)\n",
    "            loss_list.append(loss.item())\n",
    "    avg_acc = sum(acc_list)/params['epochs']\n",
    "    return loss.item(), avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Local model aggregation and sending of global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524127a9-5a79-4f05-998f-fad5af9f2d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "   \n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "            global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))],\n",
    "                                        0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "            \n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c95b03c",
   "metadata": {},
   "source": [
    "Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98027b5-60a9-4d75-ad7e-0a05ee73f3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    global_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = global_model(data.to(torch.float))\n",
    "            criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            test_loss += criterion(output, target).item()\n",
    "            # test_loss.append(criterion(output, target).item())\n",
    "            # get the index of the max log-probability\n",
    "           \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d41c640d",
   "metadata": {},
   "source": [
    "Saving and plotting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba410b2-3d15-4d92-a017-c7b58829ced7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def saving_and_plotting(time, model_lists, ltr_lists, lt_lists, at_lists, atr_lists,params):\n",
    "    # DO not save the pretrained VGG part\n",
    "    runs = len(model_lists)\n",
    "    isQuantum = params['isQuantum']\n",
    "    exp_name = f'{time}_Quantum:_{isQuantum}'\n",
    "    directory = f\"Exp:_{exp_name}\"\n",
    "    parent_dir = '/global/u2/r/rr637/QPPAI-FL/Results'\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    os.mkdir(path)\n",
    "    path_plots = path + '/Plots'\n",
    "    os.mkdir(path_plots)\n",
    "    path_models = path + '/Models'\n",
    "    os.mkdir(path_models)\n",
    "    for i in range(runs):\n",
    "        plot_acc_loss(atr_lists[i],ltr_lists[i],at_lists[i],lt_lists[i], params['isQuantum'], \n",
    "                      exp_name,f'Accuracy/Loss per Round - Iteration {i+1}',i+1)\n",
    "        torch.save(model_lists[i].net.classifier.state_dict(), f\"{path_models}/model_iteration={i}\")\n",
    "    lt_ave = list(np.average(np.array(lt_lists),axis = 0))\n",
    "    at_ave = list(np.average(np.array(at_lists),axis = 0))\n",
    "    ltr_ave = list(np.average(np.array(ltr_lists),axis = 0))\n",
    "    atr_ave = list(np.average(np.array(atr_lists),axis = 0))\n",
    "    if runs>1:\n",
    "        plot_acc_loss(atr_ave,ltr_ave,at_ave,lt_ave,params['isQuantum'],exp_name,\n",
    "                      f'Averaged Accuracy/Loss per Round After {runs} Iterations',0)\n",
    "    \n",
    "  \n",
    "        \n",
    "\n",
    "# Save lists as CSV files\n",
    "    with open(path + \"/avg_loss_test.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(lt_ave)\n",
    "\n",
    "    with open(path + \"/avg_loss_train.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(ltr_ave)\n",
    "\n",
    "    with open(path + \"/avg_acc_test.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(at_ave)\n",
    "\n",
    "    with open(path + \"/avg_acc_train.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(atr_ave)\n",
    "\n",
    "    # Save the dictionary as a CSV file\n",
    "    with open(path + \"/params.csv\", \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for key, value in params.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_epsilon_v_acc(epsilon_list, acc_list,exp_index,title):\n",
    "    plt.scatter(epsilon_list,acc_list),\n",
    "    plt.xlabel('epsilon'),\n",
    "    plt.ylabel('final_test_accuracy'),\n",
    "    plt.title(title),\n",
    "    plt.savefig(f\"Results/Epsilon_vs_Acc/{exp_index}_avg_epsilon_vs_accuracy.png\"),\n",
    "    plt.show()\n",
    "       \n",
    "def plot_acc_loss(tr_a,tr_l,t_a,t_l,is_Quantum, exp_name,title,i):\n",
    "    plt.plot(tr_a,label = \"train accuracy\"),\n",
    "    plt.plot(tr_l,label = \"train loss\"),\n",
    "    plt.plot(t_a,label = \"test accuracy\"),\n",
    "    plt.plot(t_l,label = \"test loss\"),\n",
    "    plt.xlabel('Round'),\n",
    "    plt.ylabel('Accuracy/Loss'),\n",
    "    plt.title(title),\n",
    "    plt.legend(),\n",
    "    plt.savefig(f\"Results/Exp:_{exp_name}/Plots/Acc_loss_plot_{i}.png\"),\n",
    "    plt.show()             \n",
    "             \n",
    "             \n",
    "    \n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67bcd103",
   "metadata": {},
   "source": [
    "Main function for QFL-DP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ab82a-af3e-4a68-80fc-3619b16a3f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def main(params):\n",
    "\n",
    "    if params['isQuantum']:\n",
    "        global_model = QuantumTransfer().to(device)\n",
    "        client_models = [QuantumTransfer().to(device)\n",
    "                     for _ in range(params['selected'])]\n",
    "    else:\n",
    "        global_model = ClassicalTransfer().to(device)\n",
    "        client_models = [ClassicalTransfer().to(device)\n",
    "                     for _ in range(params['selected'])]\n",
    "        \n",
    "    for model in client_models:\n",
    "        # initial synchronizing with global model\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "    if params['usePyvacy'] == True:\n",
    "\n",
    "        opt = [optim.DPSGD(\n",
    "            l2_norm_clip= params['l2_clip'],\n",
    "            noise_multiplier= params['noise'],\n",
    "            minibatch_size= params['mini_bs'],\n",
    "            microbatch_size= params['micro_bs'],\n",
    "            params=model.net.classifier.parameters(),\n",
    "            lr = params['lr'],\n",
    "            weight_decay= params['l2_penalty'])\n",
    "         for model in client_models]\n",
    "\n",
    "\n",
    "    else:\n",
    "        opt = [optim.SGD(model.net.classifier.parameters(), lr=params['lr']) for model in client_models]\n",
    "\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "    if params['usePyvacy']:\n",
    "        epsilon = params['epsilon']\n",
    "        delta = params['delta']\n",
    "        print(f'Achieves ({epsilon}, {delta})-DP')\n",
    "\n",
    "    for r in range(params['rounds']):\n",
    "        # select random clients\n",
    "        num_selected = params['selected']\n",
    "        client_idx = np.random.permutation(params['clients'])[:num_selected]\n",
    "        # client update\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for i in range(params['selected']):\n",
    "            loss_temp, acc_temp = client_update(client_models[i], opt[i],\n",
    "                                  train_loader[client_idx[i]], epoch=params['epochs']\n",
    "                                                , index = i, r=r)\n",
    "            loss += loss_temp\n",
    "            acc += acc_temp\n",
    "        losses_train.append(loss / params['selected'])\n",
    "        acc_train.append(acc/params['selected'])\n",
    "       \n",
    "        trained_client_models = client_models\n",
    "        trained_global_model = global_model\n",
    "        server_aggregate(trained_global_model, trained_client_models)\n",
    "        test_loss, test_acc = test(global_model, test_loader)\n",
    "        losses_test.append(test_loss)\n",
    "        acc_test.append(test_acc)\n",
    "        print(f\"loss_test_list_per_round: {losses_test}\")\n",
    "        print(f\"acc_test_list_per_round: {acc_test}\")\n",
    "    print(f\"FINAL TEST ACC : {acc_test[-1]} After {params['rounds']} Rounds\")\n",
    "\n",
    "\n",
    "    final_dict = {}\n",
    "    final_dict['lt'] = losses_test\n",
    "    final_dict['at'] = acc_test\n",
    "    final_dict['ltr'] = losses_train\n",
    "    final_dict['atr'] = acc_train\n",
    "    final_dict['model'] = global_model\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04ef330f",
   "metadata": {},
   "source": [
    "Script for running experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d4b7b-002f-45ea-a5ff-0d1b1a580461",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_index = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "if not params['eps_vs_acc']:\n",
    "    \n",
    "    lt_lists=[]\n",
    "    at_lists=[]\n",
    "    ltr_lists=[]\n",
    "    atr_lists=[]\n",
    "    model_lists = []\n",
    "    for i in range(params['runs']):\n",
    "        results = main(params)\n",
    "        lt_lists.append(results['lt'])\n",
    "        at_lists.append(results['at'])\n",
    "        ltr_lists.append(results['ltr'])\n",
    "        atr_lists.append(results['atr'])\n",
    "        model_lists.append(results['model'])\n",
    "    saving_and_plotting(exp_index, model_lists, ltr_lists, lt_lists, at_lists, atr_lists, params)\n",
    "        \n",
    "\n",
    "else:\n",
    "    fin_acc_lists =[]\n",
    "    epsilon_lists= []\n",
    "    noise_min = params['noise_min']\n",
    "    noise_max = params['noise_max']\n",
    "    noise_incr = params['noise_incr']\n",
    "    \n",
    "    for i in range(params['runs']):\n",
    "        epsilon_list = []\n",
    "        final_accuracy_list =[]\n",
    "       \n",
    "        for noise in np.arange(noise_min, noise_max, noise_incr): #exclusive\n",
    "            params['noise'] = noise\n",
    "            dict = main(params)\n",
    "            final_accuracy_list.append(dict['at'][-1])\n",
    "            epsilon = analysis.epsilon(dataset_sizes['train'],params['mini_bs'],\n",
    "                                noise, params['rounds'],params['delta'])\n",
    "            epsilon_list.append(epsilon)\n",
    "        fin_acc_lists.append(final_accuracy_list)\n",
    "        epsilon_lists.append(epsilon_list)\n",
    "    fin_acc_avg = list(np.average(np.array(fin_acc_lists),axis = 0))\n",
    "    eps_ave = list(np.average(np.array(epsilon_lists),axis = 0))  \n",
    "    print(fin_acc_lists)\n",
    "    print(fin_acc_avg)\n",
    "    print(epsilon_lists)\n",
    "    print(eps_ave)\n",
    "    runs = params['runs']\n",
    "    plot_epsilon_v_acc(eps_ave, fin_acc_avg,exp_index,f'Averaged Epsilon vs Acc After {runs} Iterations')                               \n",
    "    eps_v_acc_path = '/global/u2/r/rr637/QPPAI-FL/Results/Epsilon_vs_Acc'\n",
    "    with open(eps_v_acc_path + \"/params\" + \".txt\", \"wb\") as fp:\n",
    "        pickle.dump(params, fp)\n",
    "        \n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332f068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
